%!TEX root=../report.tex
\chapter{Introduction}\label{chp:introduction}

One of the fundamental problem in distributed computing is the so called consensus problem, that arises every time a number of processes (or agents) have to agree on some data value. In the last thirty-five years the consensus problem has been formally defined in terms of properties that must be satisfied by the algorithms trying to solve it. Since then, some results on the possibility or impossibility of consensus have also been proved and some distributed algorithms have been designed to address it with some environment constraints. Nowadays, many commercial products implements these algorithms in their core engines to ensure data is reliably stored on clusters of nodes despite unexpected crashes of the machines.\\
The goal of this work is to test some of these distributed algorithms in order to gather some statistics about their performances in different conditions, resembling environments with different degrees of criticality. For this reason, almost no details about the consensus problem itself is going to be provided in this document and the general approaches to solve such problem are assumed to be known to the reader.\\
All the tests performed on the algorithms that will be presented are black-box. No assumption has been done on the implementation language, the underlying technologies used by nodes to communicate over the network or the hardware configuration of the nodes in the cluster. For such reason we expect the designed tests to be meaningful also on every other consensus algorithm. As a consequence, the testing platform can be easily extended to support other implementations that have not been considered in this work. It is right and proper to underline that the tests performed probably do not cover the worst-case scenarios of every algorithm. In order to exploit the intrinsic criticalities of each algorithm design, a white-box test will be necessary instead.\\
The consensus algorithms chosen are Paxos and Raft. Two implementations have been considered for each of them, one developed by a big team and used in many commercial systems, while the other developed by a single person. The list of the implementations is the following:

\begin{itemize}
    \item Datastore: a NoSQL document database developed by Google, built for automatic scaling, high performance and ease of application development. It uses an optimized version of Paxos to reach consensus on objects versions. It is close-source and it is only available as a web-service provided by Google itself.
    \item Multi-paxos: an academic open-source implementation of Paxos designed to maintain a single replicated value across a cluster. The code is written in Python using the asynchronous programming model implemented by Twisted, a framework providing networking primitives, the asynchronous callback mechanism, event scheduling and the overall reactor loop.
    \item RethinkDB: an open-source scalable JSON database designed for realtime applications, built over five years by a team of database experts with the help of hundreds of contributors all around the world. The logic underlying the system relies on a C++ implementation of Raft, tightly integrated with lower-level RethinkDB subsystems, to allow replicas to elect an acting primary. 
    \item PySyncObj: a Python library providing data synchronization capability between multiple instances. It uses Raft for leader election and log replication and it offers a convenient interface to transform an arbitrary class into a replicated one.
\end{itemize}